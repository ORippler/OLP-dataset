{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25d447-26b8-4fd5-b2a9-7940b2a0da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from dataset import FabricDataset\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# define root of single fabric contained in olp-dataset\n",
    "root = \"../olp-dataset/Textile_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a7afc-50fa-4b9f-818b-6466be665dd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FabricDataset\n",
    "\n",
    "Transforms passed to `transform` are applied only once during loading (e.g. for resizing images), whereas `uncached_transforms` are applied to every sample during each call to `FabricDataset.__getitem__`.\n",
    "`load_mode` specifies whether front-light, back-light images, or both images should be loaded.\n",
    "The dataset furthermore ensures that the same operations/augmentations are applied to front-light and back-light images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d16cec-dd2b-4495-9861-548a7cd80e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncached_transforms = A.Compose([A.NoOp()])\n",
    "load_transforms = A.Compose([A.Resize(512, 512)])\n",
    "dset = FabricDataset(\n",
    "    root=root,\n",
    "    annFile=os.path.join(root, \"dataset.json\"),\n",
    "    cache=False,\n",
    "    uncached_transform=uncached_transforms,\n",
    "    transform=load_transforms,\n",
    "    load_mode=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f7164-39c3-420f-abc5-fca1cb0c60bf",
   "metadata": {},
   "source": [
    "A call to `FabricDataset.__getitem__` returns a `dict` containing the following key/value pairs:\n",
    "\n",
    "                \"image\":            loaded and transformed image\n",
    "                \"mask\":             semantic segmentation mask of the image\n",
    "                \"masks\":            binary segmentation masks of all individual defect-instances\n",
    "                \"bboxes\":           bounding boxes in coco-format of the individual defect-instances\n",
    "                \"instance_labels\":  class labels of the individual defect-instances\n",
    "                \"textile\":          the fabric the image belongs to\n",
    "                \"target\":           the, possibly transformed, image-level class-label/targ\n",
    "                \n",
    "Let's load and visualize some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ca7e0-f8db-4ead-a7f4-7458ea31ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2, **kwargs):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3898b3-bad5-4528-874f-11fb0773667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sample in enumerate(tqdm(dset)):\n",
    "    if idx == 100:\n",
    "        break\n",
    "    if (sample[\"target\"][-1] != 0) or (random.random() < 0.05):\n",
    "        fig, ax = plt.subplots(1,3)\n",
    "        fl_image = np.copy(sample[\"image\"][:,:,:-1])\n",
    "        bl_image = np.copy(sample[\"image\"][:,:,-1]) # backlight luminance is stored in the last channel of the image\n",
    "        for bbox in sample[\"bboxes\"]:\n",
    "            visualize_bbox(fl_image, bbox)\n",
    "            visualize_bbox(bl_image, bbox)\n",
    "        ax[0].imshow(fl_image)\n",
    "        ax[1].imshow(bl_image, cmap=\"gray\")\n",
    "        ax[2].imshow(sample[\"mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa570182-807a-4e98-9887-f45ea3d5d42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
