{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25d447-26b8-4fd5-b2a9-7940b2a0da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import FabricDataModule\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# define olp-dataset root\n",
    "root = \"../olp-dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a7afc-50fa-4b9f-818b-6466be665dd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FabricDataModule\n",
    "\n",
    "In order to generate overarching datasets which cover > 1 FabricDataset, we inherit from the `LightningDataModule` class and let it hold a `ConcatDataset` that contains a single `FabricDataset` per selected fabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213b841-28bf-470c-a7b1-cb08eceba216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by setting up all transforms to be passed to the individual FabricDatasets\n",
    "load_transform = A.Compose(\n",
    "    [A.Resize(896, 896)],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"coco\", label_fields=[\"instance_labels\"]\n",
    "    )\n",
    ")\n",
    "final_transform = [ToTensorV2()]\n",
    "\n",
    "final_eval_transform = []\n",
    "final_eval_transform.extend(deepcopy(final_transform))\n",
    "final_eval_transform = A.Compose(\n",
    "    final_eval_transform,\n",
    "    bbox_params=A.BboxParams(\n",
    "        format=\"coco\", label_fields=[\"instance_labels\"]\n",
    "    )\n",
    ")\n",
    "final_train_transform = [\n",
    "    A.CropNonEmptyMaskIfExists(224, 224)\n",
    "]\n",
    "\n",
    "final_train_transform.extend(deepcopy(final_transform))\n",
    "final_train_transform = A.Compose(final_train_transform,\n",
    "                                  bbox_params=A.BboxParams(\n",
    "                                      format=\"coco\", label_fields=[\"instance_labels\"]\n",
    "                                  )\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8ba86-88b4-4203-aaa0-069a272f0e9b",
   "metadata": {},
   "source": [
    "The `LightningDatamodule` possesses the same args as `FabricDataset` (as those are just forwarded).\n",
    "Additionally, we can select a range of fabrics via `textiles`, whether to `invert` the selection or not, and all other data-composition/sampling related stuff, such as the `collate_fn`, oversampling of the anomalies etc.\n",
    "\n",
    "**NOTE: If you want to use `LightningDataModule` for object detection/instance segmentation, you need to write a new collate_fn, refer https://github.com/pytorch/vision/issues/2624#issuecomment-681811444. The `FabricDataset` does provide all necessary information though on a per-sample basis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f37ff4-67a7-4e54-9a0c-af8805ebed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = FabricDataModule(\n",
    "    root=root,\n",
    "    cache=False,\n",
    "    textiles=list(range(1, 39)),\n",
    "    transform=load_transform,\n",
    "    uncached_train_transform=final_train_transform,\n",
    "    uncached_eval_transform=final_eval_transform,\n",
    "    load_mode=\"both\")\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c60d40-f77c-4f30-941d-ad91e02e40b6",
   "metadata": {},
   "source": [
    "The loaders can then be used as you would use any `DataLoader` from pytorch, i.e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2924292-e60c-418b-bfad-dec63e723ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(datamodule.train_dataloader()):\n",
    "    pass\n",
    "    # do the training loop\n",
    "for _ in tqdm(datamodule.val_dataloader()):\n",
    "    pass\n",
    "    # do the validation loop\n",
    "for _ in tqdm(datamodule.test_dataloader()):\n",
    "    pass\n",
    "    # do the testing loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bbbe5-270a-4ef6-ba52-04c9b0b4e188",
   "metadata": {},
   "source": [
    "Alternatively, they can of course be used with pytorch-lightning, which was used by is in the original manuscript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
